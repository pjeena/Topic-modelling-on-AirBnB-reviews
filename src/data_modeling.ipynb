{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyush/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/piyush/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/piyush/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/piyush/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/piyush/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from umap import UMAP\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/paris_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1406845, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.date)\n",
    "df['year'] = df['date'].dt.year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
       "       2020, 2021, 2022, 2023], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2022    394577\n",
       "2019    220245\n",
       "2018    174277\n",
       "2021    161016\n",
       "2017    122830\n",
       "2020     83678\n",
       "2016     82636\n",
       "2023     77870\n",
       "2015     52798\n",
       "2014     23088\n",
       "2013      9167\n",
       "2012      3386\n",
       "2011      1031\n",
       "2010       240\n",
       "2009         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1406845, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    \"\"\"Remove urls from a string\"\"\"\n",
    "    import re\n",
    "    return re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def lowercase(text):\n",
    "    \"\"\"Remove urls from a string\"\"\"\n",
    "\n",
    "    return ' '.join(x.lower() for x in text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comments'] = df['comments'].astype(str)\n",
    "df['comments'] = df['comments'].apply(remove_html_tags)\n",
    "df['comments'] = df['comments'].apply(remove_urls)\n",
    "df['comments'] = df['comments'].apply(lowercase)\n",
    "df['date']= pd.to_datetime(df['date'])\n",
    "\n",
    "\n",
    "\n",
    "#test = df.groupby('listing_id')['comments'].apply(list).reset_index(name='new')\n",
    "#docs = test['new'].apply(lambda x : \" \".join(x)).values\n",
    "#df = df[df['year'] == 2023].reset_index(drop=True)\n",
    "\n",
    "df = df[df['year'].isin([2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023])].reset_index(drop=True)\n",
    "df = df.groupby('year').apply(lambda x: x.sample(5000,random_state=100)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2013    5000\n",
       "2014    5000\n",
       "2015    5000\n",
       "2016    5000\n",
       "2017    5000\n",
       "2018    5000\n",
       "2019    5000\n",
       "2020    5000\n",
       "2021    5000\n",
       "2022    5000\n",
       "2023    5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>599419</td>\n",
       "      <td>4592866</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>5141358</td>\n",
       "      <td>Oksana</td>\n",
       "      <td>i booked lilian's apartment for my parents - t...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1679711</td>\n",
       "      <td>8743133</td>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>3674456</td>\n",
       "      <td>Wei Chian</td>\n",
       "      <td>it was a last minute reservation (day before) ...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1780833</td>\n",
       "      <td>9186405</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>1820498</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>what a wonderful flat. well-located, perfectly...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111270</td>\n",
       "      <td>5275567</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>4801752</td>\n",
       "      <td>Juliane</td>\n",
       "      <td>we had a wonderful time at francois' place. th...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>874864</td>\n",
       "      <td>7792037</td>\n",
       "      <td>2013-10-03</td>\n",
       "      <td>8083127</td>\n",
       "      <td>Danny</td>\n",
       "      <td>audrey is a wonderful host and her apartment i...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54995</th>\n",
       "      <td>607213527992148908</td>\n",
       "      <td>810015717863921137</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>305984574</td>\n",
       "      <td>Myriam</td>\n",
       "      <td>merci pour votre accueil.</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54996</th>\n",
       "      <td>24538105</td>\n",
       "      <td>828061132627903355</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>220718628</td>\n",
       "      <td>Renata</td>\n",
       "      <td>the stay was overall okay, get what we’ve paid...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54997</th>\n",
       "      <td>54390678</td>\n",
       "      <td>815078458292521587</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>326207448</td>\n",
       "      <td>Anna</td>\n",
       "      <td>a nice place to spend a few days in paris. jus...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54998</th>\n",
       "      <td>25180580</td>\n",
       "      <td>795483123881965037</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>191056209</td>\n",
       "      <td>Trin</td>\n",
       "      <td>guillaume is super wonderful host. we got a sh...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54999</th>\n",
       "      <td>15899047</td>\n",
       "      <td>825271770236489368</td>\n",
       "      <td>2023-02-12</td>\n",
       "      <td>426634313</td>\n",
       "      <td>Lucas</td>\n",
       "      <td>ótimo</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               listing_id                  id       date  reviewer_id  \\\n",
       "0                  599419             4592866 2013-05-14      5141358   \n",
       "1                 1679711             8743133 2013-11-15      3674456   \n",
       "2                 1780833             9186405 2013-12-11      1820498   \n",
       "3                  111270             5275567 2013-06-22      4801752   \n",
       "4                  874864             7792037 2013-10-03      8083127   \n",
       "...                   ...                 ...        ...          ...   \n",
       "54995  607213527992148908  810015717863921137 2023-01-22    305984574   \n",
       "54996            24538105  828061132627903355 2023-02-16    220718628   \n",
       "54997            54390678  815078458292521587 2023-01-29    326207448   \n",
       "54998            25180580  795483123881965037 2023-01-02    191056209   \n",
       "54999            15899047  825271770236489368 2023-02-12    426634313   \n",
       "\n",
       "      reviewer_name                                           comments  year  \n",
       "0            Oksana  i booked lilian's apartment for my parents - t...  2013  \n",
       "1         Wei Chian  it was a last minute reservation (day before) ...  2013  \n",
       "2              Jeff  what a wonderful flat. well-located, perfectly...  2013  \n",
       "3           Juliane  we had a wonderful time at francois' place. th...  2013  \n",
       "4             Danny  audrey is a wonderful host and her apartment i...  2013  \n",
       "...             ...                                                ...   ...  \n",
       "54995        Myriam                          merci pour votre accueil.  2023  \n",
       "54996        Renata  the stay was overall okay, get what we’ve paid...  2023  \n",
       "54997          Anna  a nice place to spend a few days in paris. jus...  2023  \n",
       "54998          Trin  guillaume is super wonderful host. we got a sh...  2023  \n",
       "54999         Lucas                                              ótimo  2023  \n",
       "\n",
       "[55000 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 179 default stopwords. They are ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#NLTK English stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# Print out the NLTK default stopwords\n",
    "print(f'There are {len(stopwords)} default stopwords. They are {stopwords}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1 = pd.read_csv('../data/app_c.csv',usecols=['name']).rename(columns={\"name\": \"name\"})\n",
    "names_2 = pd.read_csv('../data/prenom.csv',usecols=['prenom']).rename(columns={\"prenom\": \"name\"})\n",
    "names_3 = pd.read_csv('../data/Prenoms.csv',sep=';' , encoding='latin-1',usecols=['01_prenom']).rename(columns={\"01_prenom\": \"name\"})\n",
    "names_4 = pd.read_csv('../data/patronymes.csv', usecols=['patronyme']).rename(columns={\"patronyme\": \"name\"})\n",
    "\n",
    "names = pd.concat([names_1, names_2, names_3, names_4])\n",
    "name_list = names['name'].str.lower().tolist()\n",
    "names_list = list(map(( lambda x: str(x)+'s'), name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_related_words = ['stay', 'airbnb', 'paris', 'would', 'time', 'apartment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2504241 stopwords.\n"
     ]
    }
   ],
   "source": [
    "# Expand stopwords\n",
    "stopwords.extend(name_list + names_list + airbnb_related_words)\n",
    "print(f'There are {len(stopwords)} stopwords.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension reduction\n",
    "from umap import UMAP\n",
    "# Clustering\n",
    "from hdbscan import HDBSCAN\n",
    "# Count vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from cuml.manifold import UMAP\n",
    "#from cuml.cluster import HDBSCAN\n",
    "\n",
    "\n",
    "# Initiate UMAP\n",
    "umap_model = UMAP(n_neighbors=15, \n",
    "                  n_components=5, \n",
    "                  min_dist=0.0, \n",
    "                  metric='cosine', \n",
    "                  random_state=100)\n",
    "# Count vectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate UMAP\n",
    "umap_model = UMAP(n_neighbors=15, \n",
    "                  n_components=5, \n",
    "                  min_dist=0.0, \n",
    "                  metric='cosine', \n",
    "                  random_state=100)\n",
    "# Count vectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.8)\n",
    "\n",
    "# Initiate BERTopic\n",
    "topic_model = BERTopic(umap_model=umap_model, \n",
    "                       vectorizer_model=vectorizer_model, \n",
    "#                      min_topic_size=200,\n",
    "#                       top_n_words=4,\n",
    "                       language=\"multilingual\",\n",
    "                       calculate_probabilities=False,\n",
    "                       representation_model=representation_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = df.comments\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "1228.9107899665833\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Run BERTopic model\n",
    "topics = topic_model.fit_transform(docs)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>30030</td>\n",
       "      <td>-1_appartement_comfortable_recommend_bed</td>\n",
       "      <td>[appartement, comfortable, recommend, bed, two...</td>\n",
       "      <td>[we had an amazing time at julieta’s apartment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1604</td>\n",
       "      <td>0_spacieux_lumineux_emplacement_goût</td>\n",
       "      <td>[spacieux, lumineux, emplacement, goût, confor...</td>\n",
       "      <td>[très bel appartement, propre et bien situé !,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>1_using_bnb_airbnbs_booking</td>\n",
       "      <td>[using, bnb, airbnbs, booking, next, bed, lite...</td>\n",
       "      <td>[this was one of the best air bnb experiences ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>948</td>\n",
       "      <td>2_propre_confortable_hôte_agencé</td>\n",
       "      <td>[propre, confortable, hôte, agencé, commerces,...</td>\n",
       "      <td>[super séjour, calme, studio très propre et fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>906</td>\n",
       "      <td>3_recommend_beautiful_comfortable_equipped</td>\n",
       "      <td>[recommend, beautiful, comfortable, equipped, ...</td>\n",
       "      <td>[the flat is brilliantly located if you're loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>851</td>\n",
       "      <td>4_dirty_odeur_bathroom_chauffage</td>\n",
       "      <td>[dirty, odeur, bathroom, chauffage, logement, ...</td>\n",
       "      <td>[les + emplacement parfait arrivée bien organi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>589</td>\n",
       "      <td>5_hôtel_déjeuner_literie_équipe</td>\n",
       "      <td>[hôtel, déjeuner, literie, équipe, confortable...</td>\n",
       "      <td>[super hôtel, très bon week end à l’hôtel rege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>542</td>\n",
       "      <td>6_parís_amazing_museums_distance</td>\n",
       "      <td>[parís, amazing, museums, distance, cosy, reco...</td>\n",
       "      <td>[such a lovely place! it’s very petit but you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>532</td>\n",
       "      <td>7_commerces_facilement_confortable_métros</td>\n",
       "      <td>[commerces, facilement, confortable, métros, s...</td>\n",
       "      <td>[très bel appartement dans un quartier agréabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>492</td>\n",
       "      <td>8_shopping_courtyard_wonderful_museums</td>\n",
       "      <td>[shopping, courtyard, wonderful, museums, bed,...</td>\n",
       "      <td>[we had a wonderful time in paris staying in l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>483</td>\n",
       "      <td>9_subway_options_food_position</td>\n",
       "      <td>[subway, options, food, position, stop, multip...</td>\n",
       "      <td>[great location. many restaurants and grocery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>471</td>\n",
       "      <td>10_next_charming_weekend_recommend</td>\n",
       "      <td>[next, charming, weekend, recommend, walking, ...</td>\n",
       "      <td>[we had a wonderful time staying at dylan’s fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>459</td>\n",
       "      <td>11_recommandons_lumineux_adultes_confortable</td>\n",
       "      <td>[recommandons, lumineux, adultes, confortable,...</td>\n",
       "      <td>[nous avons passé un très bon séjour, l'appart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>431</td>\n",
       "      <td>12_cœur_profiter_toits_confortable</td>\n",
       "      <td>[cœur, profiter, toits, confortable, lumineux,...</td>\n",
       "      <td>[super séjour chez valeria, emplacement idéal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>424</td>\n",
       "      <td>13_personnel_confortable_accueillant_privée</td>\n",
       "      <td>[personnel, confortable, accueillant, privée, ...</td>\n",
       "      <td>[parfait! accueil sympathique, chambre agréabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>388</td>\n",
       "      <td>14_equipped_perfectly_romantic_distance</td>\n",
       "      <td>[equipped, perfectly, romantic, distance, bed,...</td>\n",
       "      <td>[мы с мужем очень рекомендуем эту студию в кач...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>385</td>\n",
       "      <td>15_return_definitely_hospitaliere_equipped</td>\n",
       "      <td>[return, definitely, hospitaliere, equipped, s...</td>\n",
       "      <td>[we had the most wonderful time. the apartment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>357</td>\n",
       "      <td>16_effiel_distance_grocery_sparkling</td>\n",
       "      <td>[effiel, distance, grocery, sparkling, bedroom...</td>\n",
       "      <td>[victoria's appartment is just won-der-ful!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>309</td>\n",
       "      <td>17_staying_airport_accommodating_arrived</td>\n",
       "      <td>[staying, airport, accommodating, arrived, eat...</td>\n",
       "      <td>[my girlfriend and i stayed at maxim’s place f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>305</td>\n",
       "      <td>18_hostess_attentive_highly_recommendations</td>\n",
       "      <td>[hostess, attentive, highly, recommendations, ...</td>\n",
       "      <td>[juliane è un host perfetto! gentile e molto d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                          Name  \\\n",
       "0      -1  30030      -1_appartement_comfortable_recommend_bed   \n",
       "1       0   1604          0_spacieux_lumineux_emplacement_goût   \n",
       "2       1    976                   1_using_bnb_airbnbs_booking   \n",
       "3       2    948              2_propre_confortable_hôte_agencé   \n",
       "4       3    906    3_recommend_beautiful_comfortable_equipped   \n",
       "5       4    851              4_dirty_odeur_bathroom_chauffage   \n",
       "6       5    589               5_hôtel_déjeuner_literie_équipe   \n",
       "7       6    542              6_parís_amazing_museums_distance   \n",
       "8       7    532     7_commerces_facilement_confortable_métros   \n",
       "9       8    492        8_shopping_courtyard_wonderful_museums   \n",
       "10      9    483                9_subway_options_food_position   \n",
       "11     10    471            10_next_charming_weekend_recommend   \n",
       "12     11    459  11_recommandons_lumineux_adultes_confortable   \n",
       "13     12    431            12_cœur_profiter_toits_confortable   \n",
       "14     13    424   13_personnel_confortable_accueillant_privée   \n",
       "15     14    388       14_equipped_perfectly_romantic_distance   \n",
       "16     15    385    15_return_definitely_hospitaliere_equipped   \n",
       "17     16    357          16_effiel_distance_grocery_sparkling   \n",
       "18     17    309      17_staying_airport_accommodating_arrived   \n",
       "19     18    305   18_hostess_attentive_highly_recommendations   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [appartement, comfortable, recommend, bed, two...   \n",
       "1   [spacieux, lumineux, emplacement, goût, confor...   \n",
       "2   [using, bnb, airbnbs, booking, next, bed, lite...   \n",
       "3   [propre, confortable, hôte, agencé, commerces,...   \n",
       "4   [recommend, beautiful, comfortable, equipped, ...   \n",
       "5   [dirty, odeur, bathroom, chauffage, logement, ...   \n",
       "6   [hôtel, déjeuner, literie, équipe, confortable...   \n",
       "7   [parís, amazing, museums, distance, cosy, reco...   \n",
       "8   [commerces, facilement, confortable, métros, s...   \n",
       "9   [shopping, courtyard, wonderful, museums, bed,...   \n",
       "10  [subway, options, food, position, stop, multip...   \n",
       "11  [next, charming, weekend, recommend, walking, ...   \n",
       "12  [recommandons, lumineux, adultes, confortable,...   \n",
       "13  [cœur, profiter, toits, confortable, lumineux,...   \n",
       "14  [personnel, confortable, accueillant, privée, ...   \n",
       "15  [equipped, perfectly, romantic, distance, bed,...   \n",
       "16  [return, definitely, hospitaliere, equipped, s...   \n",
       "17  [effiel, distance, grocery, sparkling, bedroom...   \n",
       "18  [staying, airport, accommodating, arrived, eat...   \n",
       "19  [hostess, attentive, highly, recommendations, ...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [we had an amazing time at julieta’s apartment...  \n",
       "1   [très bel appartement, propre et bien situé !,...  \n",
       "2   [this was one of the best air bnb experiences ...  \n",
       "3   [super séjour, calme, studio très propre et fo...  \n",
       "4   [the flat is brilliantly located if you're loo...  \n",
       "5   [les + emplacement parfait arrivée bien organi...  \n",
       "6   [super hôtel, très bon week end à l’hôtel rege...  \n",
       "7   [such a lovely place! it’s very petit but you ...  \n",
       "8   [très bel appartement dans un quartier agréabl...  \n",
       "9   [we had a wonderful time in paris staying in l...  \n",
       "10  [great location. many restaurants and grocery ...  \n",
       "11  [we had a wonderful time staying at dylan’s fl...  \n",
       "12  [nous avons passé un très bon séjour, l'appart...  \n",
       "13  [super séjour chez valeria, emplacement idéal ...  \n",
       "14  [parfait! accueil sympathique, chambre agréabl...  \n",
       "15  [мы с мужем очень рекомендуем эту студию в кач...  \n",
       "16  [we had the most wonderful time. the apartment...  \n",
       "17  [victoria's appartment is just won-der-ful!!! ...  \n",
       "18  [my girlfriend and i stayed at maxim’s place f...  \n",
       "19  [juliane è un host perfetto! gentile e molto d...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Topics over time\n",
    "topics_over_time = topic_model.topics_over_time(df['comments'], \n",
    "                                                df['date'], \n",
    "                                                global_tuning=True, \n",
    "                                              evolution_tuning=True,\n",
    "                                                nr_bins=11)\n",
    "# Take a look at the data\n",
    "topics_over_time.head()\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time.Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topic over time\n",
    "topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_over_time(topics_over_time, topics=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "topic_model.save(\"../model/paris/model_dir\", serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = BERTopic.load(\"/Users/piyush/Desktop/dsml_Portfolio/new_project/model/model_dir/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "drt = pd.read_parquet('../data/paris_reviews_preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1 = pd.read_csv('../data/app_c.csv',usecols=['name']).rename(columns={\"name\": \"name\"})\n",
    "names_2 = pd.read_csv('../data/prenom.csv',usecols=['prenom']).rename(columns={\"prenom\": \"name\"})\n",
    "names_3 = pd.read_csv('../data/Prenoms.csv',sep=';' , encoding='latin-1',usecols=['01_prenom']).rename(columns={\"01_prenom\": \"name\"})\n",
    "names_4 = pd.read_csv('../data/patronymes.csv', usecols=['patronyme']).rename(columns={\"patronyme\": \"name\"})\n",
    "\n",
    "names = pd.concat([names_1, names_2, names_3, names_4])\n",
    "name_list = names['name'].str.lower().tolist()\n",
    "names_list = list(map(( lambda x: str(x)+'s'), name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #NLTK English stopwords\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        airbnb_related_words = ['stay', 'airbnb', 'paris', 'would', 'time', 'apartment']\n",
    "        names_and_surnames = pd.read_csv('data/names_and_surnames.csv')\n",
    "\n",
    "        # Expand stopwords\n",
    "        stopwords.extend(names_and_surnames + airbnb_related_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from umap import UMAP\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "\n",
    "def train_bertopic(data):\n",
    "    try:\n",
    "        # Initiate UMAP\n",
    "        umap_model = UMAP(n_neighbors=15, \n",
    "                        n_components=5, \n",
    "                        min_dist=0.0, \n",
    "                        metric='cosine', \n",
    "                        random_state=100)\n",
    "        \n",
    "\n",
    "\n",
    "        #NLTK English stopwords\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        airbnb_related_words = ['stay', 'airbnb', 'paris', 'would', 'time', 'apartment']\n",
    "        names_and_surnames = pd.read_csv('../data/names_and_surnames.csv')\n",
    "        # Expand stopwords\n",
    "        stopwords.extend(list(names_and_surnames['names_&_surnames']) + airbnb_related_words)\n",
    "\n",
    "\n",
    "        vectorizer_model = CountVectorizer(stop_words=stopwords)\n",
    "        representation_model = MaximalMarginalRelevance(diversity=0.8)\n",
    "\n",
    "        # Initiate BERTopic\n",
    "        topic_model = BERTopic(umap_model=umap_model, \n",
    "                            vectorizer_model=vectorizer_model, \n",
    "        #                      min_topic_size=200,\n",
    "        #                       top_n_words=4,\n",
    "                            language=\"multilingual\",\n",
    "                            calculate_probabilities=True,\n",
    "                            representation_model=representation_model)\n",
    "\n",
    "\n",
    "\n",
    "        import time\n",
    "        start = time.time()\n",
    "\n",
    "\n",
    "        # Run BERTopic model\n",
    "        topics,_ = topic_model.fit_transform(data)\n",
    "\n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "\n",
    "        # Return the trained model and topics\n",
    "        return topic_model, topics\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during BERTopic training: {e}\")\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    parquet_file = \"data/paris_reviews_preprocessed.parquet\"\n",
    "\n",
    "    try:\n",
    "        # Process the Parquet file\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "        docs = df.comments\n",
    "\n",
    "        # Train the BERTopic model\n",
    "        model, topics = train_bertopic(docs)\n",
    "\n",
    "        # Print the topics or perform further analysis\n",
    "        print(topics)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during data processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "    parquet_file = \"../data/paris_reviews_preprocessed.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "        df = pd.read_parquet(parquet_file)\n",
    "        docs = df.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i booked lilian's apartment for my parents - t...\n",
       "1        it was a last minute reservation (day before) ...\n",
       "2        what a wonderful flat. well-located, perfectly...\n",
       "3        we had a wonderful time at francois' place. th...\n",
       "4        audrey is a wonderful host and her apartment i...\n",
       "                               ...                        \n",
       "54995                            merci pour votre accueil.\n",
       "54996    the stay was overall okay, get what we’ve paid...\n",
       "54997    a nice place to spend a few days in paris. jus...\n",
       "54998    guillaume is super wonderful host. we got a sh...\n",
       "54999                                                ótimo\n",
       "Name: comments, Length: 55000, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9947509765625\n"
     ]
    }
   ],
   "source": [
    "model, topics = train_bertopic(docs[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>78</td>\n",
       "      <td>-1_bed_recommend_stayed_métro</td>\n",
       "      <td>[bed, recommend, stayed, métro, cosy, food, co...</td>\n",
       "      <td>[the flat is brilliantly located if you're loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0_recommend_could_breakfast_romantic</td>\n",
       "      <td>[recommend, could, breakfast, romantic, bed, s...</td>\n",
       "      <td>[i booked lilian's apartment for my parents - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1_recommend_distance_ppls_wifi</td>\n",
       "      <td>[recommend, distance, ppls, wifi, courtyard, b...</td>\n",
       "      <td>[apartment is small but is as described. walls...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                  Name  \\\n",
       "0     -1     78         -1_bed_recommend_stayed_métro   \n",
       "1      0     12  0_recommend_could_breakfast_romantic   \n",
       "2      1     10        1_recommend_distance_ppls_wifi   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [bed, recommend, stayed, métro, cosy, food, co...   \n",
       "1  [recommend, could, breakfast, romantic, bed, s...   \n",
       "2  [recommend, distance, ppls, wifi, courtyard, b...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [the flat is brilliantly located if you're loo...  \n",
       "1  [i booked lilian's apartment for my parents - ...  \n",
       "2  [apartment is small but is as described. walls...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
