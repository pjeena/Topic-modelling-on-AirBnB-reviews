{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def download_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception if request was unsuccessful\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error occurred during data download: {e}\")\n",
    "\n",
    "def gzip_data(data):\n",
    "    try:\n",
    "        compressed_data = io.BytesIO()\n",
    "        with gzip.GzipFile(fileobj=compressed_data, mode='wb') as f:\n",
    "            f.write(data)\n",
    "        return compressed_data.getvalue()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during data compression: {e}\")\n",
    "\n",
    "def read_csv_data(gzipped_data):\n",
    "    try:\n",
    "        with gzip.GzipFile(fileobj=io.BytesIO(gzipped_data), mode='rb') as f:\n",
    "            df = pd.read_csv(f)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during CSV data reading: {e}\")\n",
    "\n",
    "def save_as_parquet(df, output_file):\n",
    "    try:\n",
    "        df.to_parquet(output_file)\n",
    "        print(f\"Data saved in Parquet format: {output_file}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during Parquet file saving: {e}\")\n",
    "\n",
    "def main():\n",
    "    url = \"http://data.insideairbnb.com/united-states/dc/washington-dc/2023-03-19/data/reviews.csv.gz\"\n",
    "    output_file = \"data.parquet\"\n",
    "\n",
    "    try:\n",
    "        # Download data\n",
    "        data = download_data(url)\n",
    "\n",
    "        # Gzip data\n",
    "        gzipped_data = gzip_data(data)\n",
    "\n",
    "        # Read in CSV format\n",
    "        df = read_csv_data(gzipped_data)\n",
    "\n",
    "        # Save as Parquet\n",
    "        save_as_parquet(df, output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during data processing: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " url = \"http://data.insideairbnb.com/united-states/dc/washington-dc/2023-03-19/data/reviews.csv.gz\"\n",
    "data = download_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzipped_data = gzip_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error occurred during CSV data reading: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mread_csv_data\u001b[0;34m(gzipped_data)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mwith\u001b[39;00m gzip\u001b[39m.\u001b[39mGzipFile(fileobj\u001b[39m=\u001b[39mio\u001b[39m.\u001b[39mBytesIO(gzipped_data), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 26\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(f)\n\u001b[1;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:548\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:637\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:2017\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m read_csv_data(gzipped_data)\n",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m, in \u001b[0;36mread_csv_data\u001b[0;34m(gzipped_data)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m     28\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError occurred during CSV data reading: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Error occurred during CSV data reading: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "df = read_csv_data(gzipped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def download_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception if request was unsuccessful\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error occurred during data download: {e}\")\n",
    "\n",
    "def gzip_data(data):\n",
    "    try:\n",
    "        compressed_data = io.BytesIO()\n",
    "        with gzip.GzipFile(fileobj=compressed_data, mode='wb') as f:\n",
    "            f.write(data)\n",
    "        return compressed_data.getvalue()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during data compression: {e}\")\n",
    "\n",
    "def save_as_csv(gzipped_data, output_file):\n",
    "    try:\n",
    "        with gzip.GzipFile(fileobj=io.BytesIO(gzipped_data), mode='rb') as f:\n",
    "            df = pd.read_csv(f)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved in CSV format: {output_file}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during CSV file saving: {e}\")\n",
    "\n",
    "def main():\n",
    "    url = \"http://data.insideairbnb.com/united-states/dc/washington-dc/2023-03-19/data/reviews.csv.gz\"\n",
    "    output_file = \"data.csv\"\n",
    "\n",
    "    try:\n",
    "        # Download data\n",
    "        data = download_data(url)\n",
    "\n",
    "        # Gzip data\n",
    "        gzipped_data = gzip_data(data)\n",
    "\n",
    "        # Save as CSV\n",
    "        save_as_csv(gzipped_data, output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during data processing: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = download_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzipped_data = gzip_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error occurred during CSV file saving: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m, in \u001b[0;36msave_as_csv\u001b[0;34m(gzipped_data, output_file)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mwith\u001b[39;00m gzip\u001b[39m.\u001b[39mGzipFile(fileobj\u001b[39m=\u001b[39mio\u001b[39m.\u001b[39mBytesIO(gzipped_data), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 26\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(f)\n\u001b[1;32m     27\u001b[0m df\u001b[39m.\u001b[39mto_csv(output_file, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:548\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:637\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/dsml_Portfolio/new_project/venv/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:2017\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m save_as_csv(gzipped_data, output_file)\n",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36msave_as_csv\u001b[0;34m(gzipped_data, output_file)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mData saved in CSV format: \u001b[39m\u001b[39m{\u001b[39;00moutput_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError occurred during CSV file saving: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Error occurred during CSV file saving: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "output_file = \"data.csv\"\n",
    "save_as_csv(gzipped_data, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved: unzipped_data.csv\n",
      "Data converted to Parquet: converted_data.parquet\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def download_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception if request was unsuccessful\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error occurred during data download: {e}\")\n",
    "\n",
    "def unzip_data(data):\n",
    "    try:\n",
    "        with gzip.GzipFile(fileobj=io.BytesIO(data), mode='rb') as f:\n",
    "            unzipped_data = f.read()\n",
    "        return unzipped_data\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during data unzipping: {e}\")\n",
    "\n",
    "def save_data(data, output_file):\n",
    "    try:\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(data)\n",
    "        print(f\"Data saved: {output_file}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during data saving: {e}\")\n",
    "\n",
    "def convert_to_parquet(csv_file, parquet_file):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df.to_parquet(parquet_file)\n",
    "        print(f\"Data converted to Parquet: {parquet_file}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred during Parquet conversion: {e}\")\n",
    "\n",
    "def main():\n",
    "    url = \"http://data.insideairbnb.com/united-states/dc/washington-dc/2023-03-19/data/reviews.csv.gz\"\n",
    "    output_file = \"data/paris_reviews_unzipped_data.csv\"\n",
    "    parquet_file = \"data/paris_reviews.parquet\"\n",
    "\n",
    "    try:\n",
    "        # Download data\n",
    "        data = download_data(url)\n",
    "\n",
    "        # Unzip data\n",
    "        unzipped_data = unzip_data(data)\n",
    "\n",
    "        # Save data\n",
    "        save_data(unzipped_data, output_file)\n",
    "\n",
    "        # Convert to Parquet\n",
    "        convert_to_parquet(output_file, parquet_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during data processing: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/piyush/Desktop/dsml_Portfolio/new_project/data/paris_reviews_unzipped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330237, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_parquet('../data/paris_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330237, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I slept in Heather and Vasa's room only for 3 nights.\\r<br/>I met them and they are very helpful and kind.\\r<br/>The house is really few minutes walking from the most important monuments and museums.\\r<br/>For my next time in DC I'll sure come back to them for my accomodation.\\r<br/>\\r<br/>Thanks Heather and Vasa, I really appreciate it..\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.comments[257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
